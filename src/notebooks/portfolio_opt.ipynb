{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588b4c98d3734abc",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "from enum import Enum, auto\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bf219-0abd-4547-a920-082f608bea57",
   "metadata": {},
   "source": [
    "<h4>Менять активы для которых будет проведен анализ тут BASE_ASSETS</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60960ba4-a005-421e-b922-07baf2184708",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ASSETS: List[str] = [\n",
    "    \"BTC\", \"ETH\", \"XRP\", \"SOL\", \"TRX\", \"TON\", \"LINK\", \"AAVE\",\n",
    "    \"ONDO\", \"ENA\", \"MOVE\", \"HYPE\", \"UNI\", \"TAO\", \"MKR\", \"USDT\", \"USDC\", \"DAI\"\n",
    "]\n",
    "\n",
    "SYMBOLS: List[str] = [\n",
    "    f\"{asset}USDT\" for asset in BASE_ASSETS\n",
    "] # создаем список тикеров (будем строить портфели из активов, которые торгуются против USDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048e4e06-556d-4958-9015-f37c8d42b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    r\"/data/currencies/provided_data.csv\"\n",
    ")\n",
    "\n",
    "tss: List[pd.Series] = []\n",
    "\n",
    "for i in range(len(df.columns) // 2):\n",
    "    df_slice = df.iloc[:, i*2:i*2+2].copy()\n",
    "    currency_name: str = [col for col in df_slice.columns if not col.startswith(\"date\")][0]\n",
    "    df_slice.columns = df_slice.iloc[0, :]\n",
    "    df_slice = df_slice.iloc[1:]\n",
    "    df_slice.to_csv(f\"C:/Users/mihai/PycharmProjects/crypto_portfolio_opt/data/{currency_name}_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce26388-ad83-4800-825f-ccf24d16c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451e508-3ed9-47ec-9e80-3f3775a7ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec035a3-53c3-4155-9dff-52093abf90b5",
   "metadata": {},
   "source": [
    "<h4>Выгрузим данные о торгах</h4>\n",
    "\n",
    "https://binance-docs.github.io/apidocs/spot/en/#kline-candlestick-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec304b-bee5-4d1c-8a84-45ffd89c8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Колонки которые приходят с api Binance\n",
    "BINANCE_KLINE_COLS: List[str] = [\n",
    "    \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"close_time\", \"quote_asset_volume\",\n",
    "    \"num_trades\", \"taker_buy_base_volume\", \"taker_buy_quote_volume\", \"unused\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS: List[str] = [\"open\", \"high\", \"low\", \"close\"] # колонки которые будут сведены к числовому типу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb554d-3c1f-4ea8-b082-e1b62411cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: List[List[float]]) -> pd.DataFrame:\n",
    "    \"\"\"Load data to dataframe and preprocess it\"\"\"\n",
    "    df: pd.DataFrame = pd.DataFrame(data, columns=BINANCE_KLINE_COLS)\n",
    "    df[\"open_time\"] = pd.to_datetime(df[\"open_time\"], unit=\"ms\")\n",
    "    df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit=\"ms\")\n",
    "\n",
    "    for col in NUMERIC_COLS:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def query_data(start_ts: float, symbol: str, interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"Загружаем свечки из Binance API для одного offset - start_ts\"\"\"\n",
    "    params: Dict[str, Any] = {\n",
    "        \"symbol\": symbol, # наименование тикера который выгружаем\n",
    "        \"interval\": interval, # интервал свечек\n",
    "        \"startTime\": int(start_ts * 1000), # timestamp в миллисекундах\n",
    "        \"limit\": 1000 # load 1000 candles at a time (max)\n",
    "    }\n",
    "    \n",
    "    data: List[List[float]] = requests.get(\"https://api.binance.com/api/v3/klines\", params=params).json()\n",
    "    df: pd.DataFrame = preprocess_data(data=data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_last_ts_from_data(df: pd.DataFrame) -> float:\n",
    "    \"\"\"Возвращает секундный timestamp последней выгруженной свечки\"\"\"\n",
    "    return df[\"close_time\"].max().timestamp()\n",
    "\n",
    "def load_data(start_time: datetime, end_time: datetime, symbol: str, interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"Загружаем данные за весь промежуток времени (start_time; end_time)\"\"\"\n",
    "    df_all: pd.DataFrame = pd.DataFrame()\n",
    "    \n",
    "    start_ts: float = start_time.timestamp() # timestamp секундный начала и конца интервала выгрузки данных\n",
    "    end_ts: float = end_time.timestamp()\n",
    "    \n",
    "    while True:\n",
    "        df: pd.DataFrame = query_data(start_ts=start_ts, symbol=symbol, interval=interval)\n",
    "        # если данных для тикера нет, тк api возвращает любые первые 1000 свечек после start_tinme => нужно выходить из цикла\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df_all = pd.concat([df_all, df])\n",
    "        last_kline_ts: float = get_last_ts_from_data(df=df)\n",
    "        \n",
    "        if last_kline_ts >= end_ts: # если мы выгрузили данных больше, чем надо, останавливаемся\n",
    "            break\n",
    "\n",
    "    # Клипнем последний датасет по нужному времени\n",
    "    return (\n",
    "        df_all[(start_time <= df_all[\"open_time\"]) & (df_all[\"close_time\"] <= end_time)]\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ea221-fc6b-4841-9f47-2485dab66f2a",
   "metadata": {},
   "source": [
    "<h4>Соберем данные для все тикеров за нужные период времени</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ec68e-2d15-48f6-96c8-560c80955e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(start_time: datetime, end_time: datetime, symbols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Функция которая соберает данные по свечкам с Binance по всем переданным symbols за промежуток времени (start_time, end_time)\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame = pd.DataFrame()\n",
    "    \n",
    "    for symbol in tqdm(SYMBOLS, desc=\"Collecting Kline data for symbols\"):\n",
    "        df_symbol: pd.DataFrame = load_data(\n",
    "            start_time=start_time, end_time=end_time, symbol=symbol, interval=\"1d\"\n",
    "        )\n",
    "        df_symbol[\"symbol\"] = symbol # добавим тикер до того как склеить все данные\n",
    "        df = pd.concat([df, df_symbol])\n",
    "\n",
    "    df_close: pd.DataFrame = df.pivot(index=\"open_time\", columns=\"symbol\", values=\"close\") # перевели данные из long в wide формат\n",
    "    return df_close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63852395-2fb2-4c29-92a8-5b67a6cee838",
   "metadata": {},
   "source": [
    "<h4>Выгружаем данные тут, можно менять даты за которые будут выгружаться данные: start_date, end_date</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20131902-26ed-4b9c-bc2d-7fd6bedb362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставим только колонку open_time и close цену, которые нам нужны для построения портфелей\n",
    "start_time: datetime = datetime(year=2023, month=1, day=1) # менять интервал можно тут\n",
    "end_time: datetime = datetime.now()\n",
    "\n",
    "df_close: pd.DataFrame = collect_data(\n",
    "    start_time=start_time, end_time=end_time, symbols=SYMBOLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6ff25-95a2-423f-bfe0-b46a6f76ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = df_close[df_close.notna().all(axis=1)]\n",
    "df_close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c0c5f-1ec7-4272-bc61-ed4efaff0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим данные по TON\n",
    "df_ton: pd.DataFrame = pd.read_csv(\"Toncoin Historical Data.csv\")\n",
    "\n",
    "df_ton[\"Date\"] = pd.to_datetime(df_ton[\"Date\"])\n",
    "df_ton = df_ton.set_index(\"Date\")\n",
    "\n",
    "df_ton.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b36ebf-a41b-40e2-a4cd-fdf7ee4d8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close[\"TONUSDT\"] = df_ton[\"Open\"]\n",
    "df_close.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999260af-5278-4f05-a6ed-fddae6b583fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем дневные log доходности\n",
    "df_returns: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "for col in df_close.columns:\n",
    "    df_returns[col] = np.log(df_close[col] / df_close[col].shift(1))\n",
    "    \n",
    "df_returns.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae5696-af7f-444b-873a-d2e332d2140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_returns, x=\"BTCUSDT\", stat=\"probability\")\n",
    "plt.title(\"BTCUSDT Daily log returns\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9956c8-1857-46e4-ae74-3e259582f96c",
   "metadata": {},
   "source": [
    "<p>Важно: два актива были залистены на Binance относительно недавно, соответсвенно у них много пропусков в данных</p>\n",
    "\n",
    "Binance, the world's largest cryptocurrency exchange, has announced that it will list TON tokens on August 8, 2024, at 10:00 UTC. Along with the listing, Binance will introduce a seed tag, and trading pairs such as TON/BTC, TON/USDT, and TON/FDUSD will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f6ccd-a0d1-4c3f-a3bf-a696c99c7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710cfbf-4864-4580-a17a-6080c0b2cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2ded8-5cbd-46d8-a491-41e55afab2cb",
   "metadata": {},
   "source": [
    "<h4>Теперь мы можем строить портфели</h4>\n",
    "\n",
    "В качестве основы мы возьмем Markowtz Portfolio theory:\n",
    "\n",
    "Предположим, что у нас нет возможности инвестировать в безрисковый актив: соотственно оптимальный порфтель - это портфель, который минимизирует дисперсию доходностей при какой-то фиксированной ожидаемой доходности:\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "    & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{V}ar(R_t) = \\mathbf{w}^T \\Sigma \\mathbf{w} \\\\\n",
    "    & \\text{subject to} & & \\mathbb{E}(R_t) = \\mathbf{\\mu}^T \\mathbf{w} = R_t \\\\\n",
    "    &&& \\sum_{j=1}^{n} w_j = 1 \\\\\n",
    "    &&& w_j \\geq 0, \\quad j=1,\\ldots,n\n",
    "    \\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0037e9a-07f7-432e-b7ca-5acff0642d32",
   "metadata": {},
   "source": [
    "<h4>Еще раз задаем список тикеров для которых будет проведен бэктест на исторических данных. Оставляйте только те активы для которых есть данные за весь промежуток иначе будут ошибки и неправильные портфели: portfolio_assets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c021a1c-b47a-4eb0-86e2-badcfe8bad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3733ee7-7d78-46fd-9469-3edb61d889a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для тикера ZETAUSDT не было данных, тк он еще не залистился на бинансе, поэтому создадим список активов для которых есть данные\n",
    "# и которые будут использоваться в построении портфеля\n",
    "portfolio_assets: List[str] = [\n",
    "    'AAVEUSDT', 'BTCUSDT', 'ENAUSDT', 'ETHUSDT', 'LINKUSDT', 'MKRUSDT',\n",
    "    'MOVEUSDT', 'SOLUSDT', 'TAOUSDT', 'TONUSDT', 'TRXUSDT', 'UNIUSDT',\n",
    "    'USDCUSDT', 'XRPUSDT'\n",
    "]\n",
    "portfolio_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e75c2-20a8-4d11-81dd-89d5568614fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix: np.ndarray = df_returns[portfolio_assets].cov() # ковариационная матрица доходностей активов\n",
    "R: np.ndarray = df_returns[portfolio_assets].mean().values # вектор средних дневных лог доходностей\n",
    "daily_target_return: float = 0.1 / 365 # доходность которую мы фиксируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f4c7d-fa9c-49e5-9cd4-3a1f20ab2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def variance_objective(W: np.ndarray) -> float:\n",
    "    \"\"\"Фукнция которую мы будем минимизировать с помощью scipy.optimize.minimize\"\"\"\n",
    "    portfolio_var: float = W @ cov_matrix @ W.T\n",
    "    return portfolio_var # -> скаляр - дисперсия доходности портфеля\n",
    "\n",
    "def weights_constraint(W: np.ndarray) -> float:\n",
    "    \"\"\"Ограничение на то, что в сумме веса нашего портфеля должны быть (мы не рассматриваем случай с возможностью шорта)\"\"\"\n",
    "    return W.sum() - 1\n",
    "\n",
    "def expected_return_constraint(W: np.ndarray) -> float:\n",
    "    return np.dot(W, R) - daily_target_return\n",
    "\n",
    "# Добавляем все ограничения в этот список\n",
    "constraints: List[Dict[str, Any]] = [\n",
    "    {\"type\": \"eq\", \"fun\": weights_constraint},\n",
    "    {\"type\": \"ineq\", \"fun\": expected_return_constraint}\n",
    "]\n",
    "\n",
    "bounds: List[Tuple[float, float]] = [\n",
    "    (0, 1) for asset in portfolio_assets\n",
    "] # создадим ограничение на каждый вес, что w_i лежит в интервале от 0 до 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ad312-1951-42cc-9a83-eeabfaf45246",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [1 / len(portfolio_assets)] * len(portfolio_assets) # задаем стартовую точку с которой солвер будет искать минимум variance_objective\n",
    "\n",
    "res = minimize(\n",
    "    fun=variance_objective,\n",
    "    x0=x0,\n",
    "    bounds=bounds,\n",
    "    constraints=constraints,\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adea98e-c161-400e-97ba-81914ac3278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x.round(3) # оптимальный портфель в таком случае"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99d6d9-cae6-487d-ab18-acfa3bc187be",
   "metadata": {},
   "source": [
    "<h4>Мы теперь умеем находить портфель, который будет минимизировать дисперсию доходности при заданом уровне ожидаемой доходности</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078fad1-14b4-4cf1-8343-d964cbda7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_annual: np.ndarray = np.sqrt(np.diag(cov_matrix) * 365)\n",
    "R_annual: np.ndarray = R * 365\n",
    "\n",
    "plt.scatter(Sigma_annual, R_annual)\n",
    "\n",
    "for i, asset in enumerate(portfolio_assets):\n",
    "    plt.annotate(\n",
    "        asset, (Sigma_annual[i], R_annual[i]), fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Portfolio assets\")\n",
    "\n",
    "plt.xlabel(\"Annualized variance of returns\")\n",
    "plt.ylabel(\"Annualized Expected returns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934f914-4ce3-42e3-ad1c-c9fa66c81daa",
   "metadata": {},
   "source": [
    "<h4>Вместо минимизации дисперсии при фиксированном доходе, мы можем максимизировать премию за риск или Sharpe Ratio</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e844502-bd07-410d-ba16-d84b33d2ddb6",
   "metadata": {},
   "source": [
    "$$\\text{Sharpe ratio} = \\frac{<W, R>}{\\sqrt{W^T \\Sigma W}} \\rightarrow max$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7958d5e-783b-499a-a9a1-fea4e2abbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_objective(W: np.ndarray) -> float:\n",
    "    sigma_p = np.sqrt(W @ cov_matrix @ W.T)\n",
    "    return -np.dot(W, R) / sigma_p # добавим минус, чтобы мы максимизировали\n",
    "\n",
    "def weights_constraint(W: np.ndarray) -> float:\n",
    "    \"\"\"Ограничение на то, что в сумме веса нашего портфеля должны быть (мы не рассматриваем случай с возможностью шорта)\"\"\"\n",
    "    return W.sum() - 1\n",
    "    \n",
    "bounds: List[Tuple[float, float]] = [\n",
    "    (0, 1) for asset in portfolio_assets\n",
    "] # создадим ограничение на каждый вес, что w_i лежит в интервале от 0 до 1\n",
    "\n",
    "# Теперь нам не нужно ограничение на фиксированную ожидаемую доходность\n",
    "constraints: List[Dict[str, Any]] = [\n",
    "    {\"type\": \"eq\", \"fun\": weights_constraint},\n",
    "]\n",
    "\n",
    "x0 = [0.1] * len(portfolio_assets) # задаем стартовую точку с которой солвер будет искать максимум sharpe_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10eb4d8-81ef-45f5-a6ac-6ae9c679a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(\n",
    "    fun=sharpe_objective,\n",
    "    x0=x0,\n",
    "    bounds=bounds,\n",
    "    constraints=constraints,\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d6b84-b7a0-425c-8eae-6e69222ad591",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"asset\": portfolio_assets,\n",
    "    \"weight_sharpe_portfolio\": res.x.round(4)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87127cc-6ea9-409b-84e6-c637fed095bc",
   "metadata": {},
   "source": [
    "Сейчас обернем всю логику с построением портфеля в одну функцию и будем калибровать порфтелю по критерию max Sharpe ratio, каждый квартал и строить доходности портфеля"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1006cb4-87e7-4df9-b43a-b20477db6c8e",
   "metadata": {},
   "source": [
    "<h4>Менять логику построения портфелей можно тут, определив свой класс который выполняет интерфейс PortfolioFinder</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ccaac-51a9-4151-a336-cdd0b36a99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class PortfolioFinder(ABC):\n",
    "    \"\"\"Cand define any objective but it must implement find_portfolio method\"\"\"\n",
    "\n",
    "    def __init__(self) -> Self:\n",
    "        super().__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def find_portfolio(self, df_returns: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Finds optimal portfolio\"\"\"\n",
    "\n",
    "\n",
    "class MaxSharpeOptimizer(PortfolioFinder):\n",
    "\n",
    "    def __init__(self) -> Self:\n",
    "        super().__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def max_sharpe_objective(W: np.array, df_returns: pd.DataFrame) -> float:\n",
    "        \"\"\"Функция которую мы максимизируем\"\"\"\n",
    "        sigma_p = np.sqrt(W @ df_returns.cov() @ W.T)\n",
    "        R = df_returns.mean()\n",
    "        return -np.dot(W, R) / sigma_p # -> максимизируем Sharpe ratio\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_constraint(W: np.ndarray) -> float:\n",
    "        return W.sum() - 1\n",
    "\n",
    "    @staticmethod\n",
    "    def hh_constraint(W: np.ndarray) -> float:\n",
    "        return -(np.sum(W**2) - 0.5)\n",
    "\n",
    "    def find_portfolio(self, df_returns: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Optimize for MaxSharpe ratio\"\"\"\n",
    "        # Задаес ограничения на веса портфеля\n",
    "        constraints = [\n",
    "            {\"type\": \"eq\", \"fun\": self.weight_constraint},\n",
    "            # {\"type\": \"ineq\", \"fun\": self.hh_constraint} # можно добавить ограничение на HH index\n",
    "        ]\n",
    "        # создадим ограничение на каждый вес, что w_i лежит в интервале от 0 до 1\n",
    "        n_assets: int = df_returns.shape[1]\n",
    "        bounds: List[Tuple[float, float]] = [(0, 1) for _ in range(n_assets)]\n",
    "\n",
    "        n_assets: int = df_returns.shape[1] # количество активов из которых строится портфель\n",
    "        x0 = [1 / n_assets] * n_assets\n",
    "        \n",
    "        res = minimize(\n",
    "            fun=self.max_sharpe_objective,\n",
    "            x0=x0,\n",
    "            bounds=bounds,\n",
    "            constraints=constraints,\n",
    "            args=(df_returns,)\n",
    "        )\n",
    "        \n",
    "        assert res.success, \"Солвер вернул ошибку, что-то не так с оптимизацией, может быть стоит попробовать другой солвер\"\n",
    "        \n",
    "        return res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a7431-6ab7-44fd-8dcf-44250c134897",
   "metadata": {},
   "source": [
    "<h4>Реализуем основной функционал бектеста портфельной стратегии</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2855075-5100-479c-aa36-47ca9d82a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, df_returns: pd.DataFrame, optimizer: PortfolioFinder) -> Self:\n",
    "        self.df_returns: pd.DataFrame = df_returns\n",
    "        self.optimizer: PortfolioFinder = optimizer\n",
    "        self.test_log: List[Dict[str, Any]] = []\n",
    "\n",
    "    def backtest(self, df_test: pd.DataFrame, W_star: np.array) -> None:\n",
    "        asset_returns: np.array = (1 + df_test).cumprod().iloc[-1].values # get asset cumulative returns on the last day\n",
    "\n",
    "        portfolio_return: float = np.dot(W_star, asset_returns)\n",
    "        portfolio_max_daily_drawdown: float = ((1 + df_test) @ W_star).min() # find the worst daily return in df_test\n",
    "        hh_index: float = np.sum(W_star**2)\n",
    "\n",
    "        self.test_log.append({\n",
    "            \"portfolio_return\": portfolio_return,\n",
    "            \"portfolio_max_daily_drawdown\": portfolio_max_daily_drawdown,\n",
    "            \"hh_index\": hh_index,\n",
    "            \"portfolio_weights\": W_star,\n",
    "            \"time\": df_test.index[-1]\n",
    "        })\n",
    "\n",
    "    def train(self, train_size: int, test_size: int, clean_log: bool = True):\n",
    "        \"\"\"Perform sliding window optimization and backtest of the strategy\"\"\"\n",
    "        if clean_log:\n",
    "            self.test_log = []\n",
    "\n",
    "        for i in tqdm(\n",
    "            range(0, self.df_returns.shape[0] - train_size - test_size, test_size)\n",
    "        ):\n",
    "            \n",
    "            df_train = self.df_returns.iloc[i:(i+train_size)].copy()\n",
    "            df_test = self.df_returns.iloc[(i+train_size):(i+train_size+test_size)].copy()\n",
    "            \n",
    "            W_star: np.array = self.optimizer.find_portfolio(df_returns=df_train)\n",
    "            self.backtest(df_test=df_test, W_star=W_star)\n",
    "\n",
    "\n",
    "    def plot_results(self) -> None:\n",
    "        \"\"\"Get data from test_log and display main metrics\"\"\"\n",
    "        df_test = pd.DataFrame(self.test_log)\n",
    "        df_test[\"cumprod_return\"] = df_test[\"portfolio_return\"].cumprod()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        ax1, ax2, ax3 = axs\n",
    "\n",
    "        df_test.plot(x=\"time\", y=\"cumprod_return\", ax=ax1, title=\"Cumulative return\")\n",
    "        df_test.plot(x=\"time\", y=\"portfolio_max_daily_drawdown\", ax=ax2, title=\"Max daily drawdown\")\n",
    "        df_test.plot(x=\"time\", y=\"hh_index\", ax=ax3, title=\"HH_index\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef6791-3924-4b11-bc00-73527f4144ae",
   "metadata": {},
   "source": [
    "Herfindahl-hirschman index - показывает насколько сконцентрирован портфель в одном активе:\n",
    "\n",
    "$$\\text{HH index} = \\sum_{i \\in I} w_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c91cf4-b0ee-45e6-91d6-45b6f32f243c",
   "metadata": {},
   "source": [
    "<h4>Запускаем бэктест портфелей с помощью MaxhSharpeOptimizer. train_size - длина тренировочного интервала, на котором считается ковариационная матрица и вектор доходностей, test_size - как часто мы держим и рекалибруем построенный на trainе портфель</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b916b-fe49-4c53-9895-2482fa102582",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer: PortfolioFinder = MaxSharpeOptimizer()\n",
    "\n",
    "trainer = Trainer(\n",
    "    df_returns=returns, optimizer=optimizer\n",
    ")\n",
    "trainer.train(train_size=10, test_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174c1c7-dd97-4d7b-b541-0f7890b0ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b29110-82d1-4835-9027-17120b41df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights: List[np.ndarray] = [log[\"portfolio_weights\"] for log in trainer.test_log]\n",
    "times: List[pd.Timestamp] = [log[\"time\"] for log in trainer.test_log]\n",
    " \n",
    "df_weights: pd.DataFrame = pd.DataFrame(weights)\n",
    "\n",
    "df_weights[\"time\"] = times\n",
    "df_weights = df_weights.set_index(\"time\")\n",
    "\n",
    "df_weights.columns = portfolio_assets\n",
    "df_weights.plot.area()\n",
    "\n",
    "plt.title(\"Динамика оптимального портфеля во времени\")\n",
    "plt.legend(loc=\"center left\",bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88be079-14de-4067-80ad-bf8a5d50ad4a",
   "metadata": {},
   "source": [
    "<h4>Оптимальный портфель сейчас со всеми активами, тк данные есть по всем из них за последние 90 дней</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0578840-cbf2-4a51-80f8-8d726eaaf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем лог доходности за последние 90 дней\n",
    "today: date = date.today()\n",
    "df_last_90days: pd.DataFrame = df_returns.loc[\n",
    "    df_returns.index > pd.Timestamp(today - timedelta(days=90)) # фильтр на последние 90 дней\n",
    "].copy()\n",
    "\n",
    "# Используем наш PortfolioFinder \n",
    "optimizer: PortfolioFinder = MaxSharpeOptimizer()\n",
    "optimal_weights: np.ndarray = optimizer.find_portfolio(\n",
    "    df_returns=df_last_90days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4395c41-6753-4279-8dec-4d12131351f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"asset\": df_last_90days.columns,\n",
    "    \"weight\": optimal_weights.round(3)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325a9af-18e9-49b6-81c1-7bba94bb1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns: np.ndarray = np.array([log[\"portfolio_return\"] for log in trainer.test_log]) * 12\n",
    "\n",
    "sharpe: float = returns.mean() / returns.std()\n",
    "sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456e32f-347e-4ae3-9ef4-a81a506819cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
